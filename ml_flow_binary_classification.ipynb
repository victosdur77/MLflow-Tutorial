{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e36302",
   "metadata": {},
   "source": [
    "# ML Flow Tutorial\n",
    "\n",
    "https://mlflow.org/docs/latest/getting-started/index.html\n",
    "\n",
    "MLflow Tracking is one of the primary service components of MLflow. In these guides, you will gain an understanding of what MLflow Tracking can do to enhance your MLOps related activities while building ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295e5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac73cd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0934ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f7e0a",
   "metadata": {},
   "source": [
    "### Experiment 1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df52d46a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468bab4",
   "metadata": {},
   "source": [
    "### Experiment 2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2742e30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       270\n",
      "           1       0.95      0.67      0.78        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.83      0.88       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db18915",
   "metadata": {},
   "source": [
    "### Experiment 3: Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3fe3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac546b4",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:blue\">Track Experiments Using MLFlow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc788a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        LogisticRegression(C=1, solver='liblinear'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='logloss'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a827a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ca91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf6243-36e0-4ea1-b302-d7eb310a2c56",
   "metadata": {},
   "source": [
    "The Tracking UI lets you visually explore your experiments and runs, as shown on top of this page.\n",
    "- Experiment-based run listing and comparison (including run comparison across multiple experiments)\n",
    "- Searching for runs by parameter or metric value\n",
    "- Visualizing run metrics\n",
    "- Downloading run results (artifacts and metadata)\n",
    "\n",
    "If you log runs to a local mlruns directory, run the following command in the directory above it, then access http://127.0.0.1:5000 in your browser.\n",
    "\n",
    "You need to run in a terminal the following code:\n",
    "\n",
    "**mlflow ui --port 5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "420f2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/31 11:19:32 INFO mlflow.tracking.fluent: Experiment with name 'MLFlow quickstart' does not exist. Creating a new experiment.\n",
      "2024/10/31 11:19:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/31 11:20:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/31 11:20:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"MLFlow quickstart\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric('accuracy', report['accuracy'])\n",
    "        mlflow.log_metric('recall_class_1', report['1']['recall'])\n",
    "        mlflow.log_metric('recall_class_0', report['0']['recall'])\n",
    "        mlflow.log_metric('f1_score_macro', report['macro avg']['f1-score'])        \n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, model_name)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, model_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7001a0-30d7-42f7-8d31-bb94f1aed3a4",
   "metadata": {},
   "source": [
    "This code automatically tracks the experiment. The following elements are logged automatically:\n",
    "- Metrics: In this case, accuracy.\n",
    "- Models: The trained model is stored along with its hyperparameters.\n",
    "- Parameters: You can also log any parameter you wish to track (e.g., sample size, learning rate).\n",
    "\n",
    "You can see the things in the link of the ui service provide by mlflow and also in a folder created in your repo. You can find all the info, where is your model locally stored, the metrics etc etc. It has created all this very fast\n",
    "\n",
    "Also you can for example load the model and make predictions for example for the XGBClassifier experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54279595-d944-41ed-8bbd-7c4d8e9cf53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/ed527754dd5b47039dfba3724d065df6/XGBClassifier'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict\n",
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06650534-4611-4925-9ca7-0742b99b9076",
   "metadata": {},
   "source": [
    "Also you can see to the experiments you have in the mlflow ui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5355ddf1-c42d-4bb6-a050-1149db00fc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='file:///mnt/c/Users/cimagroup/Documents/Repositorios/CursoMLFlow/mlruns/717667871174883574', creation_time=1730369972856, experiment_id='717667871174883574', last_update_time=1730369972856, lifecycle_stage='active', name='MLFlow quickstart', tags={}>, <Experiment: artifact_location='file:///mnt/c/Users/cimagroup/Documents/Repositorios/CursoMLFlow/mlruns/0', creation_time=1730369972807, experiment_id='0', last_update_time=1730369972807, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19b9af-6839-48ea-abfc-09b59fda05f8",
   "metadata": {},
   "source": [
    "Then you can register the model in the mlflow ui or here and easier to deploy the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
